---
title: "VAF calculation report"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---
  
  <style type="text/css">
  .main-container {
    max-width: 1200px;
    margin-left: auto;
    margin-right: auto;
  }
body{ /* Normal  */
    font-size: 16px;
}
</style>
  
<!-- to knit document:
library(rmarkdown)
rmarkdown::render("/share/ScratchGeneral/jamtor/projects/ewing_ctDNA/scripts/calculate_fusion_VAFs_single.Rmd", output_file="/share/ScratchGeneral/jamtor/projects/ewing_ctDNA/results/Rmarkdown/VAF_calculation_report.html")
-->
  
<br />
  
```{r, load_fusions, include = FALSE}

  samplename <- "409_018_DBV4V_AAGAGGCA-CTCTCTAT_L001"
  venn_cols <- c("#7C1BE2", "#1B9E77", "#EFC000FF", "blue")
  min_overlap <- 19
  disc_read_window <- 200

  home_dir <- "/share/ScratchGeneral/jamtor/"
  project_dir <- paste0(home_dir, "projects/ewing_ctDNA/")
  func_dir <- paste0(project_dir, "scripts/functions/")
  Robject_dir <- paste0(project_dir, "Rdata/", samplename, "/")
  col_dir <- paste0(home_dir, "R/colour_palettes/")

  system(paste0("mkdir -p ", Robject_dir))

  fusion_dir <- paste0(project_dir, "results/fusions/")
  bam_path <- paste0(project_dir, "results/BWA_and_picard/bams/")


  ####################################################################################
  ### 0. Load packages and functions ###
  ####################################################################################

  library(Rsamtools)
  library(rtracklayer)
  library(GenomicRanges)
  library(reshape)
  library(ggplot2)
  library(cowplot)

  create_venn <- dget(paste0(func_dir, "create_venn.R"))
  fetch_reads <- dget(paste0(func_dir, "fetch_reads.R"))
  find_overlapping_reads <- dget(paste0(func_dir, "find_overlapping_reads.R"))

  filter_overlaps <- function (reads, min_overlap) {
    
    split_reads <- split(reads, seqnames(reads))
    split_reads <- split_reads[c("chr11", "chr22")]
    split_reads <- lapply(split_reads, function(y) {
      if (length(y) > 0) {
        if (unique(seqnames(y)) == "chr11") {
          y$start_to_fusion <- y$fusion_coord - start(y)
          y$fusion_to_end <- end(y) - y$fusion_coord
        }
        else if (unique(seqnames(y)) == "chr22") {
          y$start_to_fusion <- y$fusion_coord - start(y)
          y$fusion_to_end <- end(y) - y$fusion_coord
        }
      }
      return(y)
    })
    prefilt_reads <- c(split_reads[[1]], split_reads[[2]])
    
    return(
      prefilt_reads[
        prefilt_reads$start_to_fusion >= min_overlap & 
          prefilt_reads$fusion_to_end >= min_overlap
      ]
    )
    
  }

  fetch_mate_gap <- dget(paste0(func_dir, "fetch_mate_gap.R"))
  find_spanning_discordant <- dget(paste0(func_dir, "find_spanning_discordant.R"))

  plot_cols <- read.table(
    paste0(col_dir, "labelled_colour_palette.txt"),
    sep = "\t",
    header = F,
    comment.char = "",
    fill = TRUE
  )$V1
  plot_cols <- plot_cols[c(1:3, 5, 4, 6:length(plot_cols))]


  ####################################################################################
  ### 1. Load and filter data ###
  ####################################################################################

  # load in fusions:
  fusions <- readRDS(paste0(fusion_dir, "EWSR1_GOI_fusions.Rdata"))
  fusions <- fusions$collapsed$high_conf_bp$GOI_fusions$FLI1
  fusions <- fusions[["409_018_DBV4V_AAGAGGCA-CTCTCTAT_L001"]]

  # split into chr22 and chr11 fusion positions:
  chr22_fusions <- GRanges(
    seqnames = fusions$join_chr,
    ranges = IRanges(start = fusions$join_coord, end = fusions$join_coord),
    strand = "*",
    join_chr = seqnames(fusions),
    join_coord = start(fusions)
  )
  chr11_fusions <- fusions

  # define file types to import:
  bamtypes <- list(
    concordant_pairs = "consensus.concordant.pairs.bam", 
    discordant_pairs = "consensus.discordant.bam",
    split_supp = "consensus.split.bam"
  )

  # set up scanBamParam to filter out unmapped reads:
  param <- ScanBamParam(
    flag = scanBamFlag(isUnmappedQuery = F),
    what = c(
      "rname", "pos", "qwidth", "strand", 
      "qname", "flag", "mapq", "cigar",
      "seq", "qual"
    )
  )

  if (!file.exists(paste0(Robject_dir, "VAF_calculation_bam_all_chr.Rdata"))) {
    
    # load in bam:
    unfilt_bam <- lapply(bamtypes, function(x) {
      
      bam_obj <- scanBam(
        paste0(bam_path, samplename, "/", samplename, ".", x),
        param = param
      )
      
      # convert to GRanges:
      gr <- GRanges(
        seqnames = bam_obj[[1]]$rname,
        ranges = IRanges(
          start = bam_obj[[1]]$pos, 
          width = bam_obj[[1]]$qwidth
        ),
        strand = bam_obj[[1]]$strand,
        qname = bam_obj[[1]]$qname,
        flag = bam_obj[[1]]$flag,
        mapq = bam_obj[[1]]$mapq,
        cigar = bam_obj[[1]]$cigar,
        seq = bam_obj[[1]]$seq,
        qual= bam_obj[[1]]$qual
      )
      
      return(gr)
      
    })
    
    # calculate read numbers:
    read_numbers <- data.frame(
      unfiltered = sapply(unfilt_bam, length)
    )
    read_numbers["split_pairs",] = NA
    read_numbers["non_split_concordant_pairs",] = NA

    # filter all bams:
    # initiate cluster:
    cl <- makeCluster(3)
    clusterExport(
      cl, varlist = c("unfilt_bam")
    )

    temp_bam <- parLapply(cl, unfilt_bam, function(x) {

      # remove multimapping reads (mapq score = 0):
      mmappers <- unique(x$qname[x$mapq == 0])
      res <- x[!(x$qname %in% mmappers)]
      
      # calculate read numbers:
      mmappers_removed = length(res)
    
      return(
        list(
          bam = res,
          read_no = mmappers_removed
        )
      )

    })

    stopCluster(cl)
    
    # update read number record:
    read_numbers$mmappers_removed <- c(
      sapply(temp_bam, function(x) {
        return(x$read_no)
      }),
      split_pairs = NA,
      non_split_concordant_pairs = NA
    )
    
    temp_bam <- lapply(temp_bam, function(x) return(x$bam))

    # filter concordant and discordant pairs:
    paired_bam <- temp_bam[names(temp_bam) %in% c("concordant_pairs", "discordant_pairs")]

    # initiate cluster:
    cl <- makeCluster(3)
    clusterExport(
      cl, varlist = c("paired_bam", "func_dir")
    )

    filt_bam <- lapply(paired_bam, function(x) {
      
      # remove reads with >1 supplementary alignment:
      spl <- split(x, x$qname)
      filt_spl <- spl[
        sapply(spl, function(y) {
          return(length(which(y$flag >= 2000)) <= 1)
        })
      ]
      x <- unlist(filt_spl)
      
      # record read numbers:
      read_no <- list(too_many_supp_removed = length(x))

      # remove reads with only supplementary alignments:
      spl <- split(x, x$qname)

      filt_spl <- spl[
        !(
          sapply(spl, function(y) {
            return(all(y$flag >= 2000))
          })
        )
      ]
      res <- unlist(filt_spl)
      
      # record read numbers:
      read_no$only_supp_removed <- length(res)

      # remove unpaired reads:
      fetch_reads <- dget(paste0(func_dir, "fetch_reads.R"))
      singles_vs_pairs <- fetch_reads(res)
      
      # record read numbers:
      read_no$unpaired_removed = length(singles_vs_pairs$pairs)

      return(
        list(
          bam = singles_vs_pairs$pairs,
          read_no = unlist(read_no)
        )
      )

    })
    
    stopCluster(cl)
    
    # add read numbers to record:
    temp_read_no <- rbind(
      as.data.frame(
        t(
          sapply(filt_bam, function(x) {
            return(x$read_no)
          })
        )
      ),
      data.frame(
        too_many_supp_removed = c(
          read_numbers$mmappers_removed[rownames(read_numbers) == "split_supp"], 
          NA, NA
        ), 
        only_supp_removed = c(
          read_numbers$mmappers_removed[rownames(read_numbers) == "split_supp"], 
          NA, NA
        ),
        unpaired_removed = c(
          read_numbers$mmappers_removed[rownames(read_numbers) == "split_supp"], 
          NA, NA
        )
      )
    )
    rownames(temp_read_no)[3:5] <- c(
      "split_supp", "split_pairs", "non_split_concordant_pairs"
    )
    
    # combine with other read counts:
    read_numbers <- cbind(read_numbers, temp_read_no)

    # combine read objects into list:
    bam <- list(
      concordant_pairs = filt_bam$concordant_pairs$bam,
      discordant_pairs = filt_bam$discordant_pairs$bam,
      split_supp = temp_bam$split_supp
    )

    # remove split supps not in either concordant or discordant pair elements:
    bam$split_supp <- bam$split_supp[
      bam$split_supp$qname %in% c(
        bam$concordant_pairs$qname,
        bam$discordant_pairs$qname
      )
    ]
    
    # fetch split primary pairs:
    bam$split_pairs <- c(
      bam$concordant_pairs[bam$concordant_pairs$qname %in% bam$split_supp$qname],
      bam$discordant_pairs[bam$discordant_pairs$qname %in% bam$split_supp$qname]
    )
    
    # record read numbers:
    read_numbers$unmatched_split_removed <- c(
      sapply(bam, length),
      non_split_concordant_pairs = NA
    )

    # remove split pairs from discordant pairs:
    bam$discordant_pairs <- bam$discordant_pairs[
      !(bam$discordant_pairs$qname %in% bam$split_pairs$qname)
    ]
    
    # record read numbers:
    read_numbers$split_removed_from_discordant <- c(
      sapply(bam, length),
      non_split_concordant_pairs = NA
    )
    
    # fetch non_split_concordant_pairs:
    bam$non_split_concordant_pairs <- bam$concordant_pairs[
      !(bam$concordant_pairs$qname %in% bam$split_pairs$qname)
    ]
    
    # record read numbers:
    read_numbers$split_removed_from_discordant <- sapply(bam, length)
    
    # remove pairs not mapped to either chr11 or 22:
    chr_filt_bam <- c(
      list(
        concordant_pairs = bam$concordant_pairs,
        discordant_pairs = bam$discordant_pairs,
        non_split_concordant_pairs = bam$non_split_concordant_pairs
      ),
      list(
        all_split = c(
          bam$split_pairs,
          bam$split_supp
        )
      )
    )
    spl <- lapply(chr_filt_bam, function(x) split(x, x$qname))
    
    # initiate cluster:
    cl <- makeCluster(7)
    clusterExport(
      cl, varlist = c("spl")
    )
    
    # remove concordant pairs not mapped to either chr11 or 22:
    spl$concordant_pairs <- spl$concordant_pairs[
      unlist(
        parLapply(cl, spl$concordant_pairs, function(x) {
          all(seqnames(x) %in% c("chr11", "chr22"))
        })
      )
    ]

    # remove non split concordant pairs not mapped to chr11 and 22:
    spl$non_split_concordant_pairs <- spl$non_split_concordant_pairs[
      unlist(
        parLapply(cl, spl$non_split_concordant_pairs, function(x) {
          all(seqnames(x) %in% c("chr11", "chr22"))
        })
      )
    ]
    
    # remove discordant pairs not mapped to chr11 and 22:
    spl$discordant_pairs <- spl$discordant_pairs[
      unlist(
        parLapply(cl, spl$discordant_pairs, function(x) {
          "chr11" %in% seqnames(x) & "chr22" %in% seqnames(x)
        })
      )
    ]
    
    # remove split reads not mapped to chr11 and 22:
    spl$all_split <- spl$all_split[
      unlist(
        parLapply(cl, spl$all_split, function(x) {
          "chr11" %in% seqnames(x) & "chr22" %in% seqnames(x)
        })
      )
    ]
    
    stopCluster(cl)
    
    # merge each set of reads and separate split supp and primary:
    fusion_chr_bam <- lapply(spl, function(x) unlist(x))
    fusion_chr_bam$split_supp <- bam$split_supp[
      bam$split_supp$qname %in% fusion_chr_bam$all_split$qname
    ]
    fusion_chr_bam$split_pairs <- bam$split_pairs[
      bam$split_pairs$qname %in% fusion_chr_bam$all_split$qname
    ]
    fusion_chr_bam <- fusion_chr_bam[
      !(names(fusion_chr_bam) %in% "all_split")
    ]
    
    # remove rownames:
    fusion_chr_bam <- lapply(fusion_chr_bam, function(x) {
      names(x) <- NULL
      return(x)
    })

    # record read numbers:
    temp_no <- sapply(fusion_chr_bam, length)
    read_numbers$fusion_chr_only <- temp_no[
      match(rownames(read_numbers), names(temp_no))
    ]

    saveRDS(unfilt_bam, paste0(Robject_dir, "unfiltered_VAF_calculation_reads.Rdata"))
    saveRDS(fusion_chr_bam, paste0(Robject_dir, "VAF_calculation_reads.Rdata"))
    saveRDS(read_numbers, paste0(Robject_dir, "VAF_calculation_read_nos.Rdata"))
    
  } else {

    unfilt_bam <- readRDS(paste0(Robject_dir, "unfiltered_VAF_calculation_reads.Rdata"))
    fusion_chr_bam <- readRDS(paste0(Robject_dir, "VAF_calculation_reads.Rdata"))
    read_numbers <- readRDS(paste0(Robject_dir, "VAF_calculation_read_nos.Rdata"))

  }

  # create venn diagram of filtered vs unfiltered reads:
  filt_vs_unfilt <- list(
    unfiltered = c(unfilt_bam$concordant_pairs, unfilt_bam$discordant_pairs), 
    filtered = c(fusion_chr_bam$concordant_pairs, fusion_chr_bam$discordant_pairs)
  )
  filt_vs_unfilt_venn <- create_venn(filt_vs_unfilt, venn_cols)

  # create venn diagram of split concordant pairs:
  concordant_split <- fusion_chr_bam[
    names(fusion_chr_bam) %in% c(
      "concordant_pairs", "split_pairs", "split_supp"
    )
  ]
  concordant_split_venn <- create_venn(concordant_split, venn_cols)

  # create venn diagram of non-split concordant pairs:
  concordant_non_split <- fusion_chr_bam[
    names(fusion_chr_bam) %in% c(
      "concordant_pairs", "non_split_concordant_pairs"
    )
  ]
  concordant_non_split_venn <- create_venn(concordant_non_split, venn_cols)

  # create venn diagram of discordant pairs:
  discordant <- fusion_chr_bam[
    names(fusion_chr_bam) %in% c(
      "discordant_pairs", "split_pairs", "split_supp"
    )
  ]
  discordant_venn <- create_venn(discordant, venn_cols)

  # create barplot of read filtering:
  read_numbers$type <- gsub("_", " ", rownames(read_numbers))
  colnames(read_numbers) <- gsub("_", " ", colnames(read_numbers))
  plot_df <- melt(read_numbers)
  plot_df$type <- factor(
    plot_df$type, 
    levels = c(
      "concordant pairs", "discordant pairs", "split supp", 
      "split pairs", "non split concordant pairs"
    )
  )

  # plot:
  p <- ggplot(plot_df, aes(x=variable, y=value, fill=type))
  p <- p + geom_bar(stat="identity", position = "dodge")
  p <- p + scale_y_continuous(trans='log10')
  p <- p + scale_fill_manual(values=plot_cols)
  p <- p + ylab("No. reads (log10)")
  p <- p + theme_cowplot(12)
  read_filtration_barplot <- p + theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title.x=element_blank()
  )
  
```


Number of high confidence EWSR1/FLI1 fusion detections =
**`r length(fusions)`** \

<br />

#### **Read filtering steps**

1. Removed multimapping (mapq = 0) read pairs.

2. Removed reads with > 1 supplementary alignments.

3. Removed reads with only supplementary alignments.

4. Removed unpaired reads.

5. Removed split supplementary alignments without matching primary alignment pair.

6. Removed split read pairs from discordant pairs.

6. Removed reads not mapping to either chr11 or chr22.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  read_filtration_barplot
```

 7. Created groups of concordant and discordant read pairs

 8. Created group of split primary alignment read pairs (read names fetched from split supplementary alignments)

 9. Removed split read pairs from discordant read pairs

 10. Created group of non-split concordant read pairs

 Ended up with three groups contributing to VAF calculations: \
  a) non-split concordant read pairs \
  b) non-split discordant read pairs \
  c) split read pairs (mixture of concordant and discordant pairs)

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  concordant_non_split_venn
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  concordant_split_venn
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  discordant_venn
```

<br />

#### **Read categorisation**

The following reads were separated for VAF calculations of each fusion breakpoint: \

1. Fusion supporting reads
  a) Split reads mapping over fusion breakpoints, with each overlap at least 19 bp long
either side of the breakpoint \
  b) Discordant reads spanning fusion breakpoint:
    i) one read maps completely within EWSR1, and one completely within FLI1, within 100 bp of breakpoint) \
    ii) similar to (i), but one or both non-split discordant reads overlap the breakpoint

2. Non-supporting reads
  a) Non-split reads mapping over fusion breakpoints, with each overlap at least 19 bp long either side of the breakpoint, both mapping to EWSR1 only \
  b) Non-discordant reads spanning fusion breakpoint (i.e. both reads map completely within EWSR1, either side of breakpoint) \

```

<br />

#### **VAF calculation**




