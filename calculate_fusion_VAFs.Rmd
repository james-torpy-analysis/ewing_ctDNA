---
title: "VAF calculation report"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---
  
  <style type="text/css">
  .main-container {
    max-width: 1200px;
    margin-left: auto;
    margin-right: auto;
  }
body{ /* Normal  */
    font-size: 16px;
}
</style>
  
<!-- to knit document:
library(rmarkdown)
rmarkdown::render("/share/ScratchGeneral/jamtor/projects/ewing_ctDNA/scripts/calculate_fusion_VAFs.Rmd", output_file="/share/ScratchGeneral/jamtor/projects/ewing_ctDNA/results/Rmarkdown/VAF_calculation_report.html")
-->
  
<br />
  
```{r, load_fusions, include = FALSE}

  filter_multimappers <- TRUE
  filter_max_supp_align <- 1  # make NA to switch off filter
  filter_supp_only <- TRUE
  filter_singles <- TRUE
  min_overlap <- 19
  venn_cols <- c("#7C1BE2", "#1B9E77", "#EFC000FF", "blue", "brown")
  
  home_dir <- "/share/ScratchGeneral/jamtor/"
  #home_dir <- "/Users/torpor/clusterHome/"
  project_dir <- paste0(home_dir, "projects/ewing_ctDNA/")
  func_dir <- paste0(project_dir, "scripts/functions/")
  Robject_dir <- paste0(project_dir, "Rdata/")
  
  system(paste0("mkdir -p ", Robject_dir))
  
  fusion_dir <- paste0(project_dir, "results/fusions/")
  bam_path <- paste0(project_dir, "results/BWA_and_picard/bams/")
  
  ####################################################################################
  ### 0. Load packages and functions ###
  ####################################################################################
  
  library(Rsamtools)
  library(rtracklayer)
  library(GenomicRanges)
  library(ggvenn)
  
  find_overlapping_reads <- dget(paste0(func_dir, "find_overlapping_reads.R"))
  filter_overlaps <- dget(paste0(func_dir, "filter_overlaps.R"))
  create_venn <- dget(paste0(func_dir, "create_venn.R"))
  
  
  ####################################################################################
  ### 1. Load and format data ###
  ####################################################################################

  # load in fusions:
  fusions <- readRDS(paste0(fusion_dir, "EWSR1_GOI_fusions.Rdata"))
  fusions <- fusions$collapsed$high_conf_bp$GOI_fusions$FLI1
  
  # define samplenames:
  samplenames <- names(fusions)
  
  # split into chr22 and chr11 fusion positions:
  chr22_fusions <- lapply(fusions, function(x) {
    return(
      GRanges(
        seqnames = x$join_chr,
        ranges = IRanges(start = x$join_coord, end = x$join_coord),
        strand = "*",
        join_chr = seqnames(x),
        join_coord = start(x)
      )
    )
  })
  chr11_fusions <- fusions
  
```

```{r, load_bams, include = FALSE}
  # define file types to import:
  bamtypes <- list(
    all = "consensus.bam", 
    split = "consensus.split.bam", 
    discordant = "consensus.discordant.bam"
  )
  
  # set up scanBamParam to filter out unmapped reads:
  param <- ScanBamParam(
    flag = scanBamFlag(isUnmappedQuery = F),
    what = c(
      "rname", "pos", "qwidth", "strand", 
      "qname", "flag", "mapq", "cigar",
      "seq", "qual"
    )
  )
  
  if (!file.exists(paste0(Robject_dir, "VAF_calculation_bams.Rdata"))) {
  
    # load in bam, split bam and discordant bam as GRanges:
    unfilt_bams <- lapply(samplenames, function(x) {
      
      # import bams:
      bam_temp <- lapply(bamtypes, function(y) {
        
        bam_obj <- scanBam(
          paste0(bam_path, x, "/", x, ".", y),
          param = param
        )
        
        # convert to GRanges:
        gr <- GRanges(
          seqnames = bam_obj[[1]]$rname,
          ranges = IRanges(
            start = bam_obj[[1]]$pos, 
            width = bam_obj[[1]]$qwidth
          ),
          strand = bam_obj[[1]]$strand,
          qname = bam_obj[[1]]$qname,
          flag = bam_obj[[1]]$flag,
          mapq = bam_obj[[1]]$mapq,
          cigar = bam_obj[[1]]$cigar,
          seq = bam_obj[[1]]$seq,
          qual= bam_obj[[1]]$qual
        )
        
        ######
        #gr <- gr[1:floor(length(gr)/10)]
        ######
        
        return(gr)
  
      })
      
    })
    names(unfilt_bams) <- samplenames
    
    # filter bams:
    bams <- lapply(unfilt_bams, function(x) {
      
      return(
        lapply(x, function(y) {
          
          if (filter_multimappers) {
            # remove multimapping reads (mapq score = 0):
            mmappers <- unique(y$qname[y$mapq == 0])
            y <- y[!(y$qname %in% mmappers)]
          }
          
          if (!is.na(filter_max_supp_align)) {
            # remove reads with >1 supplementary alignment:
            spl <- split(y, y$qname)
            filt_spl <- spl[
              sapply(spl, function(z) {
                return(length(which(z$flag >= 2000)) <= filter_max_supp_align)
              })
            ]
          }
          
          if (filter_supp_only) {
            # remove reads with only supplementary alignments:
            spl <- split(y, y$qname)
            filt_spl <- spl[
              sapply(spl, function(z) {
                return(length(which(z$flag < 2000)) <= 1)
              })
            ]
          }
          
          return(unlist(filt_spl))
          
        })
      )
      
    })
    saveRDS(bams, paste0(Robject_dir, "temp_bams.Rdata"))
    
    # fetch discarded reads for venn below:
    for (i in 1:length(unfilt_bams)) {
      bams[[i]]$all_discarded <- unfilt_bams[[i]]$all[
        !(unfilt_bams[[i]]$all$qname %in% bams[[i]]$all$qname)
      ]
    }
    
    for (i in 1:length(bams)) {
      
      writeLines("\n")
      
      # remove discordant reads from split reads and vice versa:
      print(
        paste0("Removing discordant from split reads for ", names(bams)[i], "...")
      )
      
      bams[[i]]$split <- bams[[i]]$split[
        !(bams[[i]]$split$qname %in% bams[[i]]$discordant$qname)
      ]
      bams[[i]]$discordant <- bams[[i]]$discordant[
        !(bams[[i]]$discordant$qname %in% bams[[i]]$split$qname)
      ]
      
      print(
        paste0("Fetching non-split non-discordant reads of ", names(bams)[i], "...")
      )
      
      # combine discordant and split qnames:
      discordant_and_split <- c(
        bams[[i]]$discordant$qname,
        bams[[i]]$split$qname
      )
      
      # fetch non discordant/split reads:
      bams[[i]]$non_discordant_or_split <- bams[[i]]$all[
        !(bams[[i]]$all$qname %in% discordant_and_split)
      ]
      
      print(
        paste0("Fetching split primary reads of ", names(bams)[i], "...")
      )
      
      # create split_primary GRanges:
      bams[[i]]$split_primary <- bams[[i]]$all[
        bams[[i]]$all$qname %in% bams[[i]]$split$qname
      ]
      bams[[i]]$split_primary <- bams[[i]]$split_primary[
        as.numeric(bams[[i]]$split_primary$flag) < 2000
      ]
      
      print(
        paste0("Separating paired and unpaired reads of ", names(bams)[i], "...")
      )
      
      # subset to separate reads:
      bams_sub <- bams[[i]][
        names(bams[[i]]) %in% c(
          "all", "split", "split_primary", "discordant", "non_discordant_or_split"
        )
      ]
      
      # isolate paired and single reads:
      bams_sub <- lapply(bams_sub, fetch_reads)
      
      # add all to central list:
      bams[[i]] <- c(
        bams[[i]],
        list(
          pairs = list(
            all = bams_sub$all$pairs,
            split = bams_sub$split$pairs,
            discordant = bams_sub$discordant$pairs,
            non_discordant_or_split = bams_sub$non_discordant_or_split$pairs,
            split_primary = bams_sub$split_primary$pairs
          )
        ),
        list(
          singles = list(
            all = bams_sub$all$singles,
            split = bams_sub$split$singles,
            discordant = bams_sub$discordant$singles,
            non_discordant_or_split = bams_sub$non_discordant_or_split$singles,
            split_primary = bams_sub$split_primary$singles
          )
        )
      )
      
    }
    
    saveRDS(bams, paste0(Robject_dir, "VAF_calculation_bams.Rdata"))
    
  } else {
    bams <- readRDS(paste0(Robject_dir, "VAF_calculation_bams.Rdata"))
  }
  
  
  # create venn diagram of filtered vs unfiltered reads:
  for (i in 1:length(bams)) {
    
    if (i==1) {
      filt_vs_unfilt <- list(
        list(
          unfiltered = unfilt_bams[[i]]$all, 
          filtered = bams[[i]]$all, 
          discarded = bams[[i]]$all_discarded
        )
      )
    } else {
      filt_vs_unfilt[[i]] <- list(
        unfiltered = unfilt_bams[[i]]$all, 
        filtered = bams[[i]]$all, 
        discarded = bams[[i]]$all_discarded
      )
    }
    
  }
  names(filt_vs_unfilt) <- names(bams)
  
  filt_vs_unfilt_venns <- lapply(filt_vs_unfilt, create_venn, venn_cols)
  
  # create venn diagram of paired vs single reads:
  for (i in 1:length(bams)) {
    
    if (i==1) {
      pairs_vs_singles <- list(
        list(
          all = bams[[i]]$all, 
          pairs = bams[[i]]$pairs$all, 
          singles = bams[[i]]$singles$all
        )
      )
    } else {
      pairs_vs_singles[[i]] <- list(
        all = bams[[i]]$all, 
        pairs = bams[[i]]$pairs$all, 
        singles = bams[[i]]$singles$all
      )
    }
    
    # mark supp reads as distinct:
    pairs_vs_singles[[i]] <- lapply(pairs_vs_singles[[i]], function(x) {
      x$qname[x$flag >= 2000] <- paste0(
        x$qname[x$flag >= 2000],
        "_supp"
      )
      return(x)
    })
    
  }
  names(pairs_vs_singles) <- names(bams)
  
  pairs_vs_singles_venns <- lapply(pairs_vs_singles, create_venn, venn_cols)
  
  # create venn diagram of paired reads:
  for (i in 1:length(bams)) {
    
    if (i==1) {
      all_pairs <- list(
        list(
          all = bams[[i]]$pairs$all, 
          split = bams[[i]]$pairs$split, 
          split_primary = bams[[i]]$pairs$split_primary,
          discordant = bams[[i]]$pairs$discordant,
          non_discordant_or_split = bams[[i]]$pairs$non_discordant_or_split
        )
      )
      names(all_pairs[[i]]) <- c(
        "all", "split supplementary\nalignment", "split primary\nalignment",
        "discordant", "non-discordant or split"
      )
    } else {
      all_pairs[[i]] <- list(
        all = bams[[i]]$pairs$all, 
        split = bams[[i]]$pairs$split, 
        split_primary = bams[[i]]$pairs$split_primary,
        discordant = bams[[i]]$pairs$discordant,
        non_discordant_or_split = bams[[i]]$pairs$non_discordant_or_split
      )
      names(all_pairs[[i]]) <- c(
        "all", "split supplementary\nalignment", "split primary\nalignment",
        "discordant", "non-discordant or split"
      )
    }
    
  }
  names(all_pairs) <- names(bams)
  
  all_pairs_venns <- lapply(all_pairs, create_venn, venn_cols)
  
  # create venn diagram of unpaired reads:
  for (i in 1:length(bams)) {
    
    if (i==1) {
      all_singles <- list(
        list(
          all = bams[[i]]$singles$all, 
          split = bams[[i]]$singles$split, 
          split_primary = bams[[i]]$singles$split_primary,
          discordant = bams[[i]]$singles$discordant,
          non_discordant_or_split = bams[[i]]$singles$non_discordant_or_split
        )
      )
      names(all_singles[[i]]) <- c(
        "all", "split supplementary\nalignment", "split primary\nalignment",
        "discordant", "non-discordant or split"
      )
    } else {
      all_singles[[i]] <- list(
        all = bams[[i]]$singles$all, 
        split = bams[[i]]$singles$split, 
        split_primary = bams[[i]]$singles$split_primary,
        discordant = bams[[i]]$singles$discordant,
        non_discordant_or_split = bams[[i]]$singles$non_discordant_or_split
      )
      names(all_singles[[i]]) <- c(
        "all", "split supplementary\nalignment", "split primary\nalignment",
        "discordant", "non-discordant or split"
      )
    }
    
  }
  names(all_singles) <- names(bams)
  
  all_singles_venns <- lapply(all_singles, create_venn, venn_cols)

  
```


```{r, find_breakpoint_overlapping_reads, include = FALSE}
  

```

```{r, find_breakpoint_spanning_reads, include = FALSE}


```

### **Example sample 409-018 (primary tumour, treatment naive, EWSR1/FLI1 fusion & STAG2** 
### **mutation detected by pathology):**

<br />

Number of high confidence EWSR1/FLI1 fusion detections =
**`r length(fusions[["409_018_DBV4V_AAGAGGCA-CTCTCTAT_L001"]])`** \

<br />

#### **QC**

```{r, echo = FALSE, message = FALSE, warning = FALSE}

  if (filter_multimappers) {
    print(
      paste0("Multimapping (mapq = 0) read pairs and reads with non-split ",
        "supplementary alignments were filtered out."
      )
    )
  }

  if (!is.na(filter_max_supp_align)) {
    print(
      paste0(
        "Read pairs with supplementary alignment numbers >  ", filter_max_supp_align,
        " were filtered out."
      )
    )
  }

if (!is.na(filter_supp_only)) {
    print(
      "Read pairs with only supplementary alignments were filtered out."
    )
  }


```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  filt_vs_unfilt_venns[["409_018_DBV4V_AAGAGGCA-CTCTCTAT_L001"]]
```

<br />

Reads were split into pairs and singles (unpaired):

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  pairs_vs_singles_venns[["409_018_DBV4V_AAGAGGCA-CTCTCTAT_L001"]]
```

<br />

Paired read breakdown:
```{r, echo = FALSE, message = FALSE, warning = FALSE}
  all_pairs_venns[["409_018_DBV4V_AAGAGGCA-CTCTCTAT_L001"]]
```

<br />

Unpaired read breakdown:
```{r, echo = FALSE, message = FALSE, warning = FALSE}
  all_singles_venns[["409_018_DBV4V_AAGAGGCA-CTCTCTAT_L001"]]
```

<br />

Separating the following reads for VAF calculations of each fusion breakpoint: \

1. Fusion supporting reads
  a) Split reads mapping over fusion breakpoints, with each overlap at least 19 bp long
either side of the breakpoint **in progress** \
  b) Discordant reads spanning fusion breakpoint (i.e. one read maps completely within
EWSR1, and one completely within FLI1) - **in progress** \

2. Non-supporting reads
  a) Non-split reads mapping over fusion breakpoints, with each overlap at least 19 bp long either side of the breakpoint, both mapping to EWSR1 only - **in progress** \
  b) Non-discordant reads spanning fusion breakpoint (i.e. both reads map completely within EWSR1, either side of breakpoint) - **in progress** \



