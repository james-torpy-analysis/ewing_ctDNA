---
title: "VAF calculation report"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
params: 
  samplename: "sample"
---
  
  <style type="text/css">
  .main-container {
    max-width: 1200px;
    margin-left: auto;
    margin-right: auto;
  }
body{ /* Normal  */
    font-size: 16px;
}
</style>
  
<!-- to knit document:
library(rmarkdown)
rmarkdown::render(
  "/share/ScratchGeneral/jamtor/projects/ewing_ctDNA/scripts/3.calculate_fusion_VAFs.Rmd", 
  params = list(samplename = "409_001_D9YW9_TCCTGAGC-CTCTCTAT_L001"),
  output_file="/share/ScratchGeneral/jamtor/projects/ewing_ctDNA/results/VAF_calculation//409_001_D9YW9_TCCTGAGC-CTCTCTAT_L001/VAF_calculation_report.html"
)
-->
  
<br />
  
```{r, load_fusions, include = FALSE}

  samplename <- "409_001_D9YW9_TCCTGAGC-CTCTCTAT_L001"
  venn_cols <- c("#7C1BE2", "#1B9E77", "#EFC000FF", "blue")
  min_overlap <- 19
  disc_read_window <- 200
  same_fusion_window <- 10
  
  #home_dir <- "/Users/torpor/clusterHome/"
  home_dir <- "/share/ScratchGeneral/jamtor/"
  project_dir <- paste0(home_dir, "projects/ewing_ctDNA/")
  func_dir <- paste0(project_dir, "scripts/functions/")
  result_dir <- paste0(project_dir, "results/")
  Robject_dir <- paste0(result_dir, "VAF_calculation/", samplename, "/Rdata/")
  table_dir <- paste0(result_dir, "VAF_calculation/", samplename, "/tables/")
  system(paste0("mkdir -p ", Robject_dir))
  system(paste0("mkdir -p ", table_dir))
  
  fusion_dir <- paste0(result_dir, "fusions/", samplename, "/")
  bam_path <- paste0(result_dir, "BWA_and_picard/bams/")
  col_dir <- paste0(home_dir, "R/colour_palettes/")
  
  
  ####################################################################################
  ### 0. Load packages and functions ###
  ####################################################################################
  
  library(Rsamtools)
  library(rtracklayer)
  library(GenomicRanges)
  library(reshape)
  library(ggplot2)
  library(cowplot)
  library(ggvenn)
  
  create_venn <- dget(paste0(func_dir, "create_venn.R"))
  fetch_reads <- dget(paste0(func_dir, "fetch_reads.R"))
  find_overlapping_reads <- dget(paste0(func_dir, "find_overlapping_reads.R"))
  
  filter_overlaps <- function(reads, min_overlap) {
    
    # split by chromosome:
    split_reads <- split(reads, seqnames(reads))
    split_reads <- split_reads[c("chr11", "chr22")]
    
    # calculate lengths from start of read to fusion, and from fusion to end:
    split_reads <- lapply(split_reads, function(y) {
      if (length(y) > 0) {
        if (unique(seqnames(y)) == "chr11") {
          y$start_to_fusion <- y$fusion_coord - start(y)
          y$fusion_to_end <- end(y) - y$fusion_coord
        } else if (unique(seqnames(y)) == "chr22") {
          y$start_to_fusion <- y$fusion_coord - start(y)
          y$fusion_to_end <- end(y) - y$fusion_coord
        }
      }
      return(y)
    })
    
    # concatentate reads back together:
    prefilt_reads <- c(split_reads[[1]], split_reads[[2]])
    
    # split by qname:
    prefilt_split <- split(prefilt_reads, prefilt_reads$qname)
    
    # filter out reads without overlaps of at least min_overlap on both sides of
    # fusion (need at least 1/2 read to satisfy this condition):
    filt_split <- lapply(prefilt_split, function(x) {
      condition_vec <- !(
        x$start_to_fusion >= min_overlap & x$fusion_to_end >= min_overlap
      )
      condition_vec[is.na(condition_vec)] <- FALSE
      if (all(condition_vec)) {
        return(NULL)
      } else {
        return(x)
      }
    })
    
    res <- unlist(
      as(
        filt_split[sapply(filt_split, function(x) !is.null(x))],
        "GRangesList"
      )
    )
    names(res) <- NULL
    
    return(res)
    
  }
  
  fetch_mate_gap <- dget(paste0(func_dir, "fetch_mate_gap.R"))
  find_spanning_discordant <- dget(paste0(func_dir, "find_spanning_discordant.R"))
  
  plot_cols <- read.table(
    paste0(col_dir, "labelled_colour_palette.txt"),
    sep = "\t",
    header = F,
    comment.char = "",
    fill = TRUE
  )$V1
  plot_cols <- plot_cols[c(1:3, 5, 4, 6:length(plot_cols))]
  
  
  ####################################################################################
  ### 1. Load and filter data ###
  ####################################################################################
  
  # load in fusions:
  fusions <- readRDS(paste0(fusion_dir, "EWSR1_GOI_fusions.Rdata"))
  fusions <- list(
    high_conf = fusions$high_conf_bp$true_positives$fusions$FLI1,
    low_conf = fusions$low_conf_bp$true_positives$fusions$FLI1
  )
  
  # make chr22 coord main fusion coord:
  fusions <- lapply(fusions, function(x) {
    return(
      GRanges(
        seqnames = x$join_chr,
        ranges = IRanges(start = x$join_coord, end = x$join_coord),
        strand = "*",
        join_chr = seqnames(x),
        join_coord = start(x)
      )
    )
  })
  
  # combine fusions with <= same_fusion_window bp difference in coord:
  fusions <- lapply(fusions, function(x) {
    
    x$remove <- FALSE
    
    for (i in 1:length(x)) {
      
      if (!(x$remove[i])) {
        
        chr22_window <- (start(x[i])-same_fusion_window):(start(x[i])+same_fusion_window)
        chr11_window <- (x[i]$join_coord-same_fusion_window):(x[i]$join_coord+same_fusion_window)
        
        # check each other fusion to see whether both chr11 and 22 coord is close
        # enough to those of another fusion to justify removing one of them:
        for (j in 1:length(x)) {
          
          if (j!=i & start(x)[j] %in% chr22_window & 
              x$join_coord[j] %in% chr11_window) {
            x$remove[j] <- TRUE
          }
          
        }
        
      }
      
    }
      
    # remove those marked as the same as another fusion:
    res <- x[!(x$remove)]
    mcols(res) <- subset(res, select = -remove)
    
    return(res)
    
  })

```

```{r, load_bams, include = FALSE}

  # define file types to import:
  bamtypes <- list(
    concordant_pairs = "consensus.concordant.pairs.bam", 
    discordant_pairs = "consensus.discordant.bam",
    split_supp = "consensus.split.bam"
  )
  
  # set up scanBamParam to filter out unmapped reads:
  param <- ScanBamParam(
    flag = scanBamFlag(isUnmappedQuery = F),
    what = c(
      "rname", "pos", "qwidth", "strand", 
      "qname", "flag", "mapq", "cigar",
      "mrnm", "mpos", "isize", "seq", "qual"
    )
  )
  
  if (!file.exists(paste0(Robject_dir, "VAF_calculation_reads.Rdata"))) {
    
    # load in bam:
    unfilt_bam <- lapply(bamtypes, function(x) {
      
      bam_obj <- scanBam(
        paste0(bam_path, samplename, "/", samplename, ".", x),
        param = param
      )
      
      # convert to GRanges:
      gr <- GRanges(
        seqnames = bam_obj[[1]]$rname,
        ranges = IRanges(
          start = bam_obj[[1]]$pos, 
          width = bam_obj[[1]]$qwidth
        ),
        strand = bam_obj[[1]]$strand,
        qname = bam_obj[[1]]$qname,
        flag = bam_obj[[1]]$flag,
        mapq = bam_obj[[1]]$mapq,
        cigar = bam_obj[[1]]$cigar,
        rnext = bam_obj[[1]]$mrnm,
        pnext = bam_obj[[1]]$mpos,
        tlen = bam_obj[[1]]$isize,
        seq = bam_obj[[1]]$seq,
        qual= bam_obj[[1]]$qual
      )
      
      return(gr)
      
    })
    
    # calculate read numbers:
    read_numbers <- data.frame(
      unfiltered = sapply(unfilt_bam, length)
    )
    read_numbers["split_pairs",] = NA
    read_numbers["non_split_concordant_pairs",] = NA
  
    # remove pairs not mapped to either chr11 or 22:
    chr_filt_bam <- list(
      concordant_pairs = unfilt_bam$concordant_pairs,
      discordant_pairs = unfilt_bam$discordant_pairs,
      split_supp = unfilt_bam$split_supp
    )
    spl <- lapply(chr_filt_bam, function(x) split(x, x$qname))
    
    # initiate cluster:
    cl <- makeCluster(7)
    clusterExport(
      cl, varlist = c("spl")
    )
    
    # remove concordant pairs not mapped to either chr11 or 22:
    spl$concordant_pairs <- spl$concordant_pairs[
      unlist(
        parLapply(cl, spl$concordant_pairs, function(x) {
          all(seqnames(x) %in% c("chr11", "chr22"))
        })
      )
    ]
    
    # remove discordant pairs not mapped to chr11 and 22:
    spl$discordant_pairs <- spl$discordant_pairs[
      unlist(
        parLapply(cl, spl$discordant_pairs, function(x) {
          "chr11" %in% seqnames(x) & "chr22" %in% seqnames(x)
        })
      )
    ]
    
    stopCluster(cl)
    
    # remove one mate of double-split read pairs:
    spl$split_supp <- lapply(spl$split_supp, function(x) {
      return(x[1])
    })
    
    # merge each set of reads and separate split supp and primary:
    chr_filt_bam <- lapply(spl, function(x) {
      x <- unlist(
        as(x, "GRangesList")
      )
      names(x) <- NULL
      return(x)
    })
    
    # update read number record:
    read_numbers$non_fusion_chr_removed <- c(
      sapply(chr_filt_bam, length),
      split_pairs = NA,
      non_split_concordant_pairs = NA
    )
    
    temp_bam <- lapply(chr_filt_bam, function(x) {
  
      # remove multimapping reads (mapq score = 0):
      mmappers <- unique(x$qname[x$mapq == 0])
      res <- x[!(x$qname %in% mmappers)]
      
      # calculate read numbers:
      mmappers_removed = length(res)
    
      return(
        list(
          bam = res,
          read_no = mmappers_removed
        )
      )
  
    })
    
    # update read number record:
    read_numbers$mmappers_removed <- c(
      sapply(temp_bam, function(x) {
        return(x$read_no)
      }),
      split_pairs = NA,
      non_split_concordant_pairs = NA
    )
    
    temp_bam <- lapply(temp_bam, function(x) return(x$bam))
  
    # filter concordant and discordant pairs:
    paired_bam <- temp_bam[names(temp_bam) %in% c("concordant_pairs", "discordant_pairs")]
    
    filt_bam <- lapply(paired_bam, function(x) {
      
      # remove reads with >1 supplementary alignment:
      spl <- split(x, x$qname)
      filt_spl <- spl[
        sapply(spl, function(y) {
          return(length(which(y$flag >= 2000)) <= 1)
        })
      ]
      x <- unlist(filt_spl)
      
      # record read numbers:
      read_no <- list(too_many_supp_removed = length(x))
  
      # remove reads with only supplementary alignments:
      spl <- split(x, x$qname)
  
      filt_spl <- spl[
        !(
          sapply(spl, function(y) {
            return(all(y$flag >= 2000))
          })
        )
      ]
      res <- unlist(filt_spl)
      
      # record read numbers:
      read_no$only_supp_removed <- length(res)
  
      # remove unpaired reads:
      fetch_reads <- dget(paste0(func_dir, "fetch_reads.R"))
      singles_vs_pairs <- fetch_reads(res)
      
      # record read numbers:
      read_no$unpaired_removed = length(singles_vs_pairs$pairs)
  
      return(
        list(
          bam = singles_vs_pairs$pairs,
          read_no = unlist(read_no)
        )
      )
  
    })
    
    # add read numbers to record:
    temp_read_no <- rbind(
      as.data.frame(
        t(
          sapply(filt_bam, function(x) {
            return(x$read_no)
          })
        )
      ),
      data.frame(
        too_many_supp_removed = c(
          read_numbers$mmappers_removed[rownames(read_numbers) == "split_supp"], 
          NA, NA
        ), 
        only_supp_removed = c(
          read_numbers$mmappers_removed[rownames(read_numbers) == "split_supp"], 
          NA, NA
        ),
        unpaired_removed = c(
          read_numbers$mmappers_removed[rownames(read_numbers) == "split_supp"], 
          NA, NA
        )
      )
    )
    rownames(temp_read_no)[3:5] <- c(
      "split_supp", "split_pairs", "non_split_concordant_pairs"
    )
    
    # combine with other read counts:
    read_numbers <- cbind(read_numbers, temp_read_no)
  
    # combine read objects into list:
    bam <- list(
      concordant_pairs = filt_bam$concordant_pairs$bam,
      discordant_pairs = filt_bam$discordant_pairs$bam,
      split_supp = temp_bam$split_supp
    )
    
    # remove split supps not in either concordant or discordant pair elements:
    bam$split_supp <- bam$split_supp[
      bam$split_supp$qname %in% c(
        bam$concordant_pairs$qname,
        bam$discordant_pairs$qname
      )
    ]
    
    # fetch split primary pairs:
    bam$split_pairs <- c(
      bam$concordant_pairs[bam$concordant_pairs$qname %in% bam$split_supp$qname],
      bam$discordant_pairs[bam$discordant_pairs$qname %in% bam$split_supp$qname]
    )
    
    # record read numbers:
    read_numbers$unmatched_split_removed <- c(
      sapply(bam, length),
      non_split_concordant_pairs = NA
    )
  
    # remove split pairs from discordant pairs:
    bam$discordant_pairs <- bam$discordant_pairs[
      !(bam$discordant_pairs$qname %in% bam$split_pairs$qname)
    ]
    
    # record read numbers:
    read_numbers$split_removed_from_discordant <- c(
      sapply(bam, length),
      non_split_concordant_pairs = NA
    )
    
    # fetch non_split_concordant_pairs:
    bam$non_split_concordant_pairs <- bam$concordant_pairs[
      !(bam$concordant_pairs$qname %in% bam$split_pairs$qname)
    ]
    
    # remove rownames:
    final_bam <- lapply(bam, function(x) {
      names(x) <- NULL
      return(x)
    })
    
    # record read numbers:
    read_numbers$split_removed_from_discordant <- sapply(final_bam, length)
  
    saveRDS(unfilt_bam, paste0(Robject_dir, "unfiltered_VAF_calculation_reads.Rdata"))
    saveRDS(final_bam, paste0(Robject_dir, "VAF_calculation_reads.Rdata"))
    saveRDS(read_numbers, paste0(Robject_dir, "VAF_calculation_read_nos.Rdata"))
    
  } else {
  
    unfilt_bam <- readRDS(paste0(Robject_dir, "unfiltered_VAF_calculation_reads.Rdata"))
    final_bam <- readRDS(paste0(Robject_dir, "VAF_calculation_reads.Rdata"))
    read_numbers <- readRDS(paste0(Robject_dir, "VAF_calculation_read_nos.Rdata"))
  
  }

```

```{r, create_venns, include = FALSE}

  # create venn diagram of filtered vs unfiltered reads:
  filt_vs_unfilt <- list(
    unfiltered = c(unfilt_bam$concordant_pairs, unfilt_bam$discordant_pairs), 
    filtered = c(final_bam$concordant_pairs, final_bam$discordant_pairs)
  )
  filt_vs_unfilt_venn <- create_venn(filt_vs_unfilt, venn_cols)

  # create venn diagram of split concordant pairs:
  concordant_split <- final_bam[
    names(final_bam) %in% c(
      "concordant_pairs", "split_pairs", "split_supp"
    )
  ]
  concordant_split_venn <- create_venn(concordant_split, venn_cols)

  # create venn diagram of non-split concordant pairs:
  concordant_non_split <- final_bam[
    names(final_bam) %in% c(
      "concordant_pairs", "non_split_concordant_pairs"
    )
  ]
  concordant_non_split_venn <- create_venn(concordant_non_split, venn_cols)

  # create venn diagram of discordant pairs:
  discordant <- final_bam[
    names(final_bam) %in% c(
      "discordant_pairs", "split_pairs", "split_supp"
    )
  ]
  discordant_venn <- create_venn(discordant, venn_cols)

  # create barplot of read filtering:
  read_numbers$type <- gsub("_", " ", rownames(read_numbers))
  colnames(read_numbers) <- gsub("_", " ", colnames(read_numbers))
  plot_df <- melt(read_numbers)
  plot_df$type <- factor(
    plot_df$type, 
    levels = c(
      "concordant pairs", "discordant pairs", "split supp", 
      "split pairs", "non split concordant pairs"
    )
  )

  # plot:
  p <- ggplot(plot_df, aes(x=variable, y=value, fill=type))
  p <- p + geom_bar(stat="identity", position = "dodge")
  p <- p + scale_y_continuous(trans='log10')
  p <- p + scale_fill_manual(values=plot_cols)
  p <- p + ylab("No. reads (log10)")
  p <- p + theme_cowplot(12)
  p <- p + theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title.x=element_blank()
  )


```{r, find_overlapping_reads, include = FALSE}

  ####################################################################################
  ### 2. find breakpoint-overlapping reads: ###
  ####################################################################################

  if (!file.exists(paste0(Robject_dir, "high_conf_overlapping_reads.Rdata"))) {
    
    fusions <- fusions$high_conf
      
    # create empty list to be filled:
    temp_list <- list(
      spanning = NULL,
      overlapping = NULL
    )
    
    for (i in 1:length(fusions)) {
      if (i==1) {
        all_reads <- list(
          list(
            non_supporting = temp_list,
            supporting = temp_list
          )
        )
      } else {
        all_reads[[i]] <- list(
          non_supporting = temp_list,
          supporting = temp_list
        )
      }
    }
    names(all_reads) <- start(fusions)
    
    # find overlaps of non-split concordant pairs with chr22 breakpoint coords, 
    # add to non_supporting$overlapping:
    
    # split concordant reads by qname:
    spl <- split(
      final_bam$non_split_concordant_pairs, 
      final_bam$non_split_concordant_pairs$qname
    )
    
    # initiate cluster:
    cl <- makeCluster(7)
    clusterExport(
      cl, varlist = c("spl")
    )
    
    for (i in 1:length(fusions)) {
      
      # find overlaps with fusion breakpoints:
      overlapping_reads <- parLapply(
        cl,
        spl,
        find_overlapping_reads,
        fusion = fusions[i],
        chromosome = "chr22"
      )
      
      overlapping_reads <- unlist(
        as(
          overlapping_reads[
            sapply(overlapping_reads, function(x) !is.null(x))
          ],
          "GRangesList"
        )
      )
      names(overlapping_reads) <- NULL
      
      if (!is.null(overlapping_reads)) {
        all_reads[[i]]$non_supporting$overlapping <- overlapping_reads
      } else {
        all_reads[[i]]$non_supporting$overlapping <- GRanges(NULL)
      }

    }
    
    stopCluster(cl)
    
    # find overlaps of split primary reads with chr22 breakpoint coords, 
    # add to supporting_$overlapping:
    spl <- split(final_bam$split_pairs, final_bam$split_pairs$qname)
    
    # initiate cluster:
    cl <- makeCluster(7)
    clusterExport(
      cl, varlist = c("spl")
    )
    
    for (i in 1:length(fusions)) {
      
      # find overlaps with fusion breakpoints:
      overlapping_reads <- parLapply(
        cl,
        spl,
        find_overlapping_reads,
        fusion = fusions[i],
        chromosome = "chr22"
      )
      
      overlapping_reads <- unlist(
        as(
          overlapping_reads[
            sapply(overlapping_reads, function(x) !is.null(x))
          ],
          "GRangesList"
        )
      )
      names(overlapping_reads) <- NULL
      
      if (!is.null(overlapping_reads)) {
        all_reads[[i]]$supporting$overlapping <- overlapping_reads
      } else {
        all_reads[[i]]$supporting$overlapping <- GRanges(NULL)
      }
      
    }
    
    # find overlaps of split primary reads with chr11 breakpoint coords, 
    # add to supporting_reads$overlapping:
    
    # find overlaps with fusion breakpoint:
    overlapping_reads <- parLapply(
      cl,
      spl,
      find_overlapping_reads,
      fusion = fusions[i],
      chromosome = "chr11"
    )
    
    stopCluster(cl)
    
    all_reads[[i]]$supporting$overlapping <- c(
      all_reads[[i]]$supporting$overlapping,
      unlist(
        as(
          overlapping_reads[
            sapply(overlapping_reads, function(x) !is.null(x))
          ],
          "GRangesList"
        )
      )
    )
    names(all_reads[[i]]$supporting$overlapping) <- NULL
    
    # filter reads:
    all_reads <- lapply(all_reads, function(x) {
      
      return(
        lapply(x, function(y) {
          
          # deduplicate reads:
          spl <- split(y$overlapping, y$overlapping$qname)
          spl <- spl[!duplicated(spl)]
          
          y$overlapping <- unlist(
            as(
              spl[sapply(spl, function(z) !is.null(z))],
              "GRangesList"
            )
          )
          names(y$overlapping) <- NULL
          
          # filter overlapping reads without at least min_overlap on both sides of fusion:
          y$overlapping <- filter_overlaps(
            reads = y$overlapping, 
            min_overlap = min_overlap
          )
          
          return(y)
          
        })
      )
      
    })

    saveRDS(all_reads, paste0(Robject_dir, "high_conf_overlapping_reads.Rdata"))

  } else {
    all_reads <- readRDS(paste0(Robject_dir, "high_conf_overlapping_reads.Rdata"))
  }

  

```{r, find_spanning_reads, include = FALSE}

  if (!file.exists(paste0(Robject_dir, "high_conf_fusion_reads.Rdata"))) {

    ####################################################################################
    ### 3. Find breakpoint-spanning reads ###
    ####################################################################################
    
    # find breakpoint-spanning reads from non-split non-discordant reads, 
    # add to spanning$non_supporting:
    
    # fetch read gaps (read + gap coords):
    # split by qname:
    spl <- split(
      final_bam$non_split_concordant_pairs, 
      final_bam$non_split_concordant_pairs$qname
    )
    
    # initiate cluster:
    cl <- makeCluster(7)
    clusterExport(
      cl, varlist = c("spl")
    )
    
    # fetch read gaps:
    non_split_concordant_gaps <- parLapply(
      cl, spl, fetch_mate_gap
    )
    
    stopCluster(cl)
    
    # merge into granges:
    non_split_concordant_gaps <- unlist(
      as(non_split_concordant_gaps, "GRangesList")
    )
    names(non_split_concordant_gaps) <- NULL
    
    # split by qname:
    spl <- split(non_split_concordant_gaps, non_split_concordant_gaps$qname)
    
    if (length(spl) > 0) {
      
      # initiate cluster:
      cl <- makeCluster(7)
      clusterExport(
        cl, varlist = c("spl")
      )
      
      for (i in 1:length(fusions)) {
        
        # find overlaps of non-supporting gaps with fusions:
        spanning_gaps <- parLapply(
          cl, 
          spl, 
          find_overlapping_reads, 
          fusions = fusions[i],
          chromosome = "chr22"
        )
        
        # merge ranges:
        spanning_gaps <- unlist(
          as(
            spanning_gaps[
              sapply(spanning_gaps, function(x) !is.null(x))
            ],
            "GRangesList"
          )
        )
        names(spanning_gaps) <- NULL
        
        stopCluster(cl)
        
        if (!is.null(spanning_gaps)) {
          
          # fetch corresponding read pairs:
          all_reads[[i]]$non_supporting$spanning <- final_bam$non_split_concordant_pairs[
            final_bam$non_split_concordant_pairs$qname %in% 
              spanning_gaps$qname
          ]
          m <- match(
            all_reads[[i]]$non_supporting$spanning$qname, spanning_gaps$qname
          )
          all_reads[[i]]$non_supporting$spanning$fusion_coord <- 
            spanning_gaps$fusion_coord[m]
          
        } else {
          all_reads[[i]]$non_supporting$spanning <- GRanges(NULL)
        }
        
      }
      
    } else {
      for (i in 1:length(fusions)) {
        all_reads[[i]]$non_supporting$spanning <- GRanges(NULL)
      }
    }
    
    # find breakpoint-spanning reads from discordant reads, 
    # add to spanning$supporting:
    spl <- split(
      final_bam$discordant_pairs, 
      final_bam$discordant_pairs$qname
    )
    
    for (i in 1:length(fusions)) {
      
      spanning_reads <- lapply(
        spl, 
        find_spanning_discordant, 
        fusions = fusions[i], 
        exp_window = disc_read_window
      )
      
      # merge to granges object:
      spanning_reads <- unlist(
        as(
          spanning_reads[
            sapply(spanning_reads, function(x) !is.null(x))
          ], "GRangesList"
        )
      )
      names(spanning_reads) <- NULL
      
      if (!is.null(overlapping_reads)) {
        all_reads[[i]]$supporting$spanning <- spanning_reads
      } else {
        all_reads[[i]]$supporting$spanning <- GRanges(NULL)
      }
      
    }

    saveRDS(all_reads, paste0(Robject_dir, "high_conf_fusion_reads.Rdata"))
    
  } else {
    
    all_reads <- readRDS(paste0(Robject_dir, "high_conf_fusion_reads.Rdata"))
    
  }

```
    

```{r, calculate_VAFS, include = FALSE}

  ####################################################################################
  ### 4. Calculate proportions of non-supporting vs supporting read pairs for each
  # sample ###
  ####################################################################################

  # combine all supporting reads, and all non-supporting reads, for each fusion:
  combined_reads <- lapply(all_reads, function(x) {
    return(
      lapply(x, function(y) {
        return(c(y$spanning, y$overlapping))
      })
    )
  })

  # check all reads are in pairs:
  pair_check <- lapply(combined_reads, function(x) {
    sapply(x, function(y) {
      spl <- split(y, y$qname)
      return(
        all(
          sapply(spl, function(z) {
            length(z) == 2
          })
        )
      )
    })
  })
    
  print(
    paste0(
      "Are all supporting reads in pairs? ", 
      all(sapply(pair_check, function(x) x[names(x) == "supporting"]))
    )
  )

  print(
    paste0(
      "Are all non-supporting reads in pairs? ", 
      all(sapply(pair_check, function(x) x[names(x) == "non_supporting"]))
    )
  )

  # save each group as sam file:
  for (i in 1:length(all_reads)) {
    for (j in 1:length(all_reads[[i]])) {
      for (k in 1:length(all_reads[[i]][[j]])) {
        
        if (length(all_reads[[i]][[j]][[k]]) > 0) {
          
          # define sam cols:
          sam <- data.frame(
            qname = all_reads[[i]][[j]][[k]]$qname,
            flag = all_reads[[i]][[j]][[k]]$flag,
            rname = seqnames(all_reads[[i]][[j]][[k]]),
            pos = start(all_reads[[i]][[j]][[k]]),
            mapq = all_reads[[i]][[j]][[k]]$mapq,
            cigar = all_reads[[i]][[j]][[k]]$cigar,
            rnext = all_reads[[i]][[j]][[k]]$rnext,
            pnext = all_reads[[i]][[j]][[k]]$pnext,
            tlen = all_reads[[i]][[j]][[k]]$tlen,
            seq = all_reads[[i]][[j]][[k]]$seq,
            qual = all_reads[[i]][[j]][[k]]$qual
          )
          
          # write sam to tab-separated file:
          write.table(
            sam,
            paste0(
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads_temp.sam"
            ),
            sep = "\t",
            quote = FALSE,
            row.names = FALSE,
            col.names = FALSE
          )
          
          # add header:
          system(
            paste0(
              "samtools view -H ", 
              bam_path, samplename, "/", samplename, ".", bamtypes[[1]],
              " > ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.sam"
            )
          )
          
          # add rest of sam:
          system(
            paste0(
              "cat ", 
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads_temp.sam", 
              " >> ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.sam"
            )
          )
          
          # convert to bam:
          system(
            paste0(
              "samtools view -bh ", 
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.sam",
              " > ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.bam"
            )
          )
          
          # sort:
          system(
            paste0(
              "samtools sort -o ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.sorted.bam ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.bam"
            )
          )
          
          # index:
          system(
            paste0(
              "samtools index ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.sorted.bam"
            )
          )
          
          # clean:
          system(
            paste0(
              "rm ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads_temp.sam ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.sam ",
              fusion_dir, "fusion_coord_", names(all_reads)[i], "_", 
              names(all_reads[[i]])[j],"_", names(all_reads[[i]][[j]])[k], 
              "_reads.bam"
            )
          )
          
        }
        
      }
    }
  }

  # keep breakpoints with greatest number of supporting reads:
  read_counts <- sapply(combined_reads, function(x) {
    return(
      sapply(x, function(y) {
        length(y)
      })
    )
  })

  final_reads <- all_reads[[which.max(read_counts["supporting",])]]
  final_combined <- combined_reads[[which.max(read_counts["supporting",])]]

  venn_reads <- list(
    supporting_spanning = final_reads$supporting$spanning,
    supporting_overlapping = final_reads$supporting$overlapping,
    non_supporting_spanning = final_reads$non_supporting$spanning,
    non_supporting_overlapping = final_reads$non_supporting$overlapping
  )
  final_venn <- create_venn(venn_reads, venn_cols)

  # calculate supporting vs non-supporting proportion:
  VAF <- round(
    length(final_combined$supporting)/length(final_combined$non_supporting)*100,
    1
  )

  # save VAF:
  write.table(
    VAF,
    paste0(table_dir, "fusion", names(final_reads), "_VAF.txt"),
    quote = F,
    row.names = F,
    col.names = F
  )

```

Number of high confidence EWSR1/FLI1 fusion detections =
**`r length(fusions$high_conf)`** \

Number of low confidence EWSR1/FLI1 fusion detections =
**`r length(fusions$low_conf)`** \

<br />

#### **Read filtering steps**

1. Removed mate of double-split supplement alignments

2. Removed multimapping (mapq = 0) read pairs.

3. Removed reads with > 1 supplementary alignments.

4. Removed reads with only supplementary alignments.

5. Removed unpaired reads.

6. Removed split supplementary alignments without matching primary alignment pair.

7. Removed split read pairs from discordant pairs.

8. Removed reads not mapping to either chr11 or chr22.

9. Created groups of concordant and discordant read pairs

10. Created group of split primary alignment read pairs (read names fetched from split supplementary alignments)

11. Created group of non-split concordant read pairs

Ended up with three groups contributing to VAF calculations: \
 a) non-split concordant read pairs \
 b) non-split discordant read pairs \
 c) split read pairs (mixture of concordant and discordant pairs)

<br />

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  read_filtration_barplot
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  log10_read_filtration_barplot
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  concordant_non_split_venn
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  concordant_split_venn
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  discordant_venn
```

<br />

#### **Read categorisation**

The following reads were separated for VAF calculations of each fusion breakpoint: \

1. Fusion supporting reads
  a) Split reads mapping over fusion breakpoints, with each overlap at least 19 bp long
either side of the breakpoint \
  b) Discordant reads spanning fusion breakpoint: \
    i) one read maps completely within EWSR1, and one completely within FLI1, within 100 bp of breakpoint) \
    ii) similar to (i), but one or both non-split discordant reads overlap the breakpoint

2. Non-supporting reads
  a) Non-split reads mapping over fusion breakpoints, with each overlap at least 19 bp long either side of the breakpoint, both mapping to EWSR1 only \
  b) Non-discordant reads spanning fusion breakpoint (i.e. both reads map completely within EWSR1, either side of breakpoint) \


<br />

#### **VAF calculation**

Fusion-associated reads: \

```{r, echo = FALSE, message = FALSE, warning = FALSE}
  final_venn
```

Final VAF = **`r VAF`**% \





